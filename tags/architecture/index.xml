<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>architecture on Lambda</title><link>/tags/architecture/</link><description>Recent content in architecture on Lambda</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 21 Nov 2022 18:53:55 +0800</lastBuildDate><atom:link href="/tags/architecture/index.xml" rel="self" type="application/rss+xml"/><item><title>AWS Architecture Swimming Australia</title><link>/blog/aws-architecture-swimming-australia/</link><pubDate>Mon, 21 Nov 2022 18:53:55 +0800</pubDate><guid>/blog/aws-architecture-swimming-australia/</guid><description>簡介 除了運動選手本身的能力以外，在接力比賽中，如何讓所有團隊都能拿到比較好的獎項，排隊伍就是個很關鍵的點
舉個例子 秒/國 美國 A 美國 B 澳洲 A 澳洲 B 選手1 2 1 選手2 3 5 選手3 2 3 選手4 1 1 合計秒 5 3 6 4 如果 美國 A VS. 澳洲 A ，美國 B VS. 澳洲 B
依照上面的隊伍排列，澳洲全輸，但是如果這樣排
秒/國 美國 A 美國 B 澳洲 A 澳洲 B 選手1 2 3 選手2 3 5 選手3 2 1 選手4 1 1 合計秒 5 3 8 2 就可以在 B 組拿到較好的成績</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/1VcpCVe3tLQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>除了運動選手本身的能力以外，在接力比賽中，如何讓所有團隊都能拿到比較好的獎項，排隊伍就是個很關鍵的點&lt;/p>
&lt;h3 id="舉個例子">舉個例子&lt;/h3>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>秒/國&lt;/th>
&lt;th>美國 A&lt;/th>
&lt;th>美國 B&lt;/th>
&lt;th>澳洲 A&lt;/th>
&lt;th>澳洲 B&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>選手1&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>選手2&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;/td>
&lt;td>5&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>選手3&lt;/td>
&lt;td>&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>3&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>選手4&lt;/td>
&lt;td>&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>合計秒&lt;/td>
&lt;td>5&lt;/td>
&lt;td>3&lt;/td>
&lt;td>6&lt;/td>
&lt;td>4&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;blockquote>
&lt;p>如果 美國 A VS. 澳洲 A ，美國 B VS. 澳洲 B&lt;/p>
&lt;/blockquote>
&lt;p>依照上面的隊伍排列，澳洲全輸，但是如果這樣排&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>秒/國&lt;/th>
&lt;th>美國 A&lt;/th>
&lt;th>美國 B&lt;/th>
&lt;th>澳洲 A&lt;/th>
&lt;th>澳洲 B&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>選手1&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>選手2&lt;/td>
&lt;td>3&lt;/td>
&lt;td>&lt;/td>
&lt;td>5&lt;/td>
&lt;td>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>選手3&lt;/td>
&lt;td>&lt;/td>
&lt;td>2&lt;/td>
&lt;td>&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>選手4&lt;/td>
&lt;td>&lt;/td>
&lt;td>1&lt;/td>
&lt;td>&lt;/td>
&lt;td>1&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>合計秒&lt;/td>
&lt;td>5&lt;/td>
&lt;td>3&lt;/td>
&lt;td>8&lt;/td>
&lt;td>2&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>就可以在 B 組拿到較好的成績&lt;/p>
&lt;h2 id="架構">架構&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/AWS-Architecture-Swimming-Australia.png" alt="Architecture">&lt;/p>
&lt;p>這裡分三個部分&lt;/p>
&lt;ul>
&lt;li>Web&lt;/li>
&lt;li>Data pipeline&lt;/li>
&lt;li>Auto training&lt;/li>
&lt;/ul>
&lt;h3 id="data-pipeline">Data pipeline&lt;/h3>
&lt;ul>
&lt;li>首先來看看上方黃線的部分
&lt;ul>
&lt;li>首先來看看上方黃線的部分，資料會由各個不同的方式以及格式 (XML, JSON) ，放到 S3 的 Landing bucket&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>再來看到左半邊紫色的線路
&lt;ul>
&lt;li>透過 AWS Glue 將資料整理成統一格式後放到 S3 的 Data Lake bucket&lt;/li>
&lt;li>AWS Glue 將資料整理資料科學家想要的樣貌後放到 S3 的 Curated bucket&lt;/li>
&lt;li>資料科學家可以透過 SageMaker notebook 連接 Athena 使用 SQL 語法做資料操作以及訓練&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="web">Web&lt;/h3>
&lt;p>關注左下角黑色線路&lt;/p>
&lt;ul>
&lt;li>使用者透過手機可以從 API Gateway 呼叫 Lambda 取得想要的資料&lt;/li>
&lt;li>其中包含使用 SageMaker 中已經訓練好的模型，Lambda 透過 Trigger SageMaker Endpoint，來獲得使用者想要的 Inference (AKA: 怎樣的隊伍排起來對這系列的比賽比較好)&lt;/li>
&lt;/ul>
&lt;h3 id="auto-training">Auto training&lt;/h3>
&lt;p>由於比賽資料常常更新，但是資料科學家不會每一次都有時間來重新 Train AI model ，所以他們讓使用者可以控制，是否使用新的資料去重新 Train 一個新的 AI model (關注綠色的線路)&lt;/p>
&lt;ul>
&lt;li>使用者 Trigger Lambda&lt;/li>
&lt;li>Lambda Trigger StepFunction&lt;/li>
&lt;li>StepFunction 將會完成一整套流程
&lt;ul>
&lt;li>使用 Athena 獲取資料 (包含最新的資料)&lt;/li>
&lt;li>使用 Training 的程式碼去重新產生 AI model&lt;/li>
&lt;li>驗證產生出來的 AI model 沒有特別的問題 (可以產出資料，且該資料沒有超出設定的預期)&lt;/li>
&lt;li>將產生出來的 AI model 部署到 Sagemaker Endpoint&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></content></item><item><title>AWS Architecture Accenture</title><link>/blog/aws-architecture-accenture/</link><pubDate>Thu, 17 Nov 2022 19:36:48 +0800</pubDate><guid>/blog/aws-architecture-accenture/</guid><description> 簡介 Accenture 是一家科技顧問公司，其服務包含管理諮詢，科技技術與業務流程外包等等，曾被稱作科技業界的麥肯錫
石油產業 在這產業，沒有精確的時間去購買原油，可能導致每年多出百萬美金的成本，如果有更加好的決策系統或是知識管理的系統就可以幫助他們省下大量的成本
關聯擷取 他們稱原油：crude，假設某文件中提到 crude A 的 density (濃度) 和 sulfur level (含硫量)，另外的文件提到 crude B 的 density (濃度) 和 sulfur level (含硫量)，還有隱含其風險值，所以，當 crude B 的 density 和 sulfur level 很接近 crude A 時，那就表示 crude A 有很高的機會擁有相同的風險值
架構 文件餵到 Lambda Lambda 用 SageMaker 中訓練好的模型取得一些 Type 、Key Facts 等等 Lambda 用 Comprehend 獲取詞語分析以及 Token ，和一些 Fact 將其整理後存到 Neptune，例如上方的關聯擷取圖 同時也會將原始資料用 ElasticSearch index 起來，方便後面的全文搜索</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/ekXdohpAy5U" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Accenture 是一家科技顧問公司，其服務包含管理諮詢，科技技術與業務流程外包等等，曾被稱作科技業界的麥肯錫&lt;/p>
&lt;h3 id="石油產業">石油產業&lt;/h3>
&lt;p>在這產業，沒有精確的時間去購買原油，可能導致每年多出百萬美金的成本，如果有更加好的決策系統或是知識管理的系統就可以幫助他們省下大量的成本&lt;/p>
&lt;h3 id="關聯擷取">關聯擷取&lt;/h3>
&lt;p>&lt;img src="/img/2022/11/CrudeRelationship.svg" alt="Crude Relationship">&lt;/p>
&lt;blockquote>
&lt;p>他們稱原油：crude，假設某文件中提到 crude A 的 density (濃度) 和 sulfur level (含硫量)，另外的文件提到 crude B 的 density (濃度) 和 sulfur level (含硫量)，還有隱含其風險值，所以，當 crude B 的 density 和 sulfur level 很接近 crude A 時，那就表示 crude A 有很高的機會擁有相同的風險值&lt;/p>
&lt;/blockquote>
&lt;h2 id="架構">架構&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/AccentureAWSArchitecture.svg" alt="Architecture">&lt;/p>
&lt;ul>
&lt;li>文件餵到 Lambda
&lt;ul>
&lt;li>Lambda 用 SageMaker 中訓練好的模型取得一些 Type 、Key Facts 等等&lt;/li>
&lt;li>Lambda 用 Comprehend 獲取詞語分析以及 Token ，和一些 Fact&lt;/li>
&lt;li>將其整理後存到 Neptune，例如上方的關聯擷取圖&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>同時也會將原始資料用 ElasticSearch index 起來，方便後面的全文搜索&lt;/li>
&lt;/ul></content></item><item><title>AWS Architecture CloudPlex Media</title><link>/blog/aws-architecture-cloudplex-media/</link><pubDate>Wed, 16 Nov 2022 21:15:50 +0800</pubDate><guid>/blog/aws-architecture-cloudplex-media/</guid><description>簡介 CloudPlex Media 提供客戶 VoD (隨選視訊) 與 Streaming (影像串流) 的服務，不僅能夠處理 DRM (數位版權管理)，還有 AI 做字幕自動產生，以及各式影像轉碼服務
架構 該服務，簡單分成三大項
Web VoD (隨選視訊) Streaming (影像串流) 我們將分開講解
Web 我們可以關注左上角藍色的線路
首先全平台的網頁 (HTML, JS, CSS) 都是放在 S3，使用 S3 靜態網頁託管的功能提供給客戶 當前端網頁載入後，所有功能包含上傳影片、轉碼、影片管理、分析等等，都是由 AWS API Gateway 去做代理，實際功能都以 AWS Lambda 去做實現 VoD 我們可以關注上方綠色的線路
當使用者使用上傳影片後，Lambda 會讓使用者上傳影片到 S3 當 S3 上傳完成後，會啟用 Media Convert 去做影片的轉碼，或是丟到 Media Package 去做 DRM 的管理 當影片轉碼完成後，會啟用 Step Function 去完成一連串的處理 例如 (關注上方黃色線路)： 使用 AWS Rekognition 去做裸露影像辨識 用 Transcribe 做語音轉文字，用 Translate 翻譯轉換後的文字，自動產生字幕 最後將資料放到該去的地方 其他人就可以透過 AWS S3 或是 CloudFront 去存取該影片 Streaming 我們可以關注下方黑色的線路</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/zqiNLMmEeSo" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>CloudPlex Media 提供客戶 VoD (隨選視訊) 與 Streaming (影像串流) 的服務，不僅能夠處理 DRM (數位版權管理)，還有 AI 做字幕自動產生，以及各式影像轉碼服務&lt;/p>
&lt;h2 id="架構">架構&lt;/h2>
&lt;p>該服務，簡單分成三大項&lt;/p>
&lt;ol>
&lt;li>Web&lt;/li>
&lt;li>VoD (隨選視訊)&lt;/li>
&lt;li>Streaming (影像串流)&lt;/li>
&lt;/ol>
&lt;p>我們將分開講解&lt;/p>
&lt;p>&lt;img src="/img/2022/11/CloudPlexMediaAWSArchitecture.svg" alt="Architecture">&lt;/p>
&lt;h3 id="web">Web&lt;/h3>
&lt;p>我們可以關注左上角藍色的線路&lt;/p>
&lt;ol>
&lt;li>首先全平台的網頁 (HTML, JS, CSS) 都是放在 S3，使用 S3 &lt;a href="https://docs.aws.amazon.com/AmazonS3/latest/userguide/WebsiteHosting.html">靜態網頁託管&lt;/a>的功能提供給客戶&lt;/li>
&lt;li>當前端網頁載入後，所有功能包含上傳影片、轉碼、影片管理、分析等等，都是由 AWS API Gateway 去做代理，實際功能都以 AWS Lambda 去做實現&lt;/li>
&lt;/ol>
&lt;h3 id="vod">VoD&lt;/h3>
&lt;p>我們可以關注上方綠色的線路&lt;/p>
&lt;ul>
&lt;li>當使用者使用上傳影片後，Lambda 會讓使用者上傳影片到 S3&lt;/li>
&lt;li>當 S3 上傳完成後，會啟用 Media Convert 去做影片的轉碼，或是丟到 Media Package 去做 DRM 的管理
&lt;ul>
&lt;li>當影片轉碼完成後，會啟用 Step Function 去完成一連串的處理&lt;/li>
&lt;li>例如 (關注上方黃色線路)：
&lt;ul>
&lt;li>使用 AWS Rekognition 去做裸露影像辨識&lt;/li>
&lt;li>用 Transcribe 做語音轉文字，用 Translate 翻譯轉換後的文字，自動產生字幕&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>最後將資料放到該去的地方&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>其他人就可以透過 AWS S3 或是 CloudFront 去存取該影片&lt;/li>
&lt;/ul>
&lt;h3 id="streaming">Streaming&lt;/h3>
&lt;p>我們可以關注下方黑色的線路&lt;/p>
&lt;ul>
&lt;li>當使用者開啟直播，前端會將影像用 RTMP 的方式串流到 Media Live&lt;/li>
&lt;li>這時候，依照觀看流量，利用 Fargate 去自動擴展，來服務觀看者&lt;/li>
&lt;/ul></content></item><item><title>AWS Architecture ITTStar AI Powered Search</title><link>/blog/aws-architecture-ittstar-ai-powered-search/</link><pubDate>Mon, 14 Nov 2022 20:44:42 +0800</pubDate><guid>/blog/aws-architecture-ittstar-ai-powered-search/</guid><description> 簡介 ITTStar 主要是幫助企業做上雲的資訊顧問服務，提供老舊系統雲端遷移以產業上雲服務，網站客戶寫很多，但是我看得懂的只有 Whirlpool 和 AT&amp;amp;T
要解決什麼問題 AI powered search 主要是做商品資訊辨識，可以想像你上傳幾張圖片，他可以幫你辨識出這是哪個品牌、哪個型號，大概的市場價格，主要提供給精品產業品牌以及零售與批發的估價師
架構 Amplify 的 App 使用 Cognito 做身份驗證 使用者上傳的影像會傳到 S3 S3 的更新會通知 Lambda 去 Trigger Rekognition 去做物品辨識 如果影像中有大量文字，他們會用 Textract 去擷取，並且去更正 Rekognition 辨識出來的資訊 可能可以知道品牌，型號，地點等等 最後把資料都丟到 DynamoDB</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/Qi9soN5bpU4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>&lt;a href="https://www.ittstar.com/">ITTStar&lt;/a> 主要是幫助企業做上雲的資訊顧問服務，提供老舊系統雲端遷移以產業上雲服務，網站客戶寫很多，但是我看得懂的只有 Whirlpool 和 AT&amp;amp;T&lt;/p>
&lt;h2 id="要解決什麼問題">要解決什麼問題&lt;/h2>
&lt;p>AI powered search 主要是做商品資訊辨識，可以想像你上傳幾張圖片，他可以幫你辨識出這是哪個品牌、哪個型號，大概的市場價格，主要提供給精品產業品牌以及零售與批發的估價師&lt;/p>
&lt;h2 id="架構">架構&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/ITTStartAIpoweredSearchArchitecture.svg" alt="Architecture">&lt;/p>
&lt;ul>
&lt;li>Amplify 的 App 使用 Cognito 做身份驗證&lt;/li>
&lt;li>使用者上傳的影像會傳到 S3&lt;/li>
&lt;li>S3 的更新會通知 Lambda 去 Trigger Rekognition 去做物品辨識&lt;/li>
&lt;li>如果影像中有大量文字，他們會用 Textract 去擷取，並且去更正 Rekognition 辨識出來的資訊
&lt;ul>
&lt;li>可能可以知道品牌，型號，地點等等&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>最後把資料都丟到 DynamoDB&lt;/li>
&lt;/ul></content></item><item><title>Chick-Fil-A AHA</title><link>/blog/aha/</link><pubDate>Sun, 13 Nov 2022 09:59:48 +0800</pubDate><guid>/blog/aha/</guid><description>簡介 Chick-fil-A 是一間總部位於美國喬治亞州 College Park 的美式連鎖速食店，以雞肉三明治為主 (圖片看起來其實是漢堡) ，目前有超過 2,200 間連鎖餐廳
遇到的問題 在速食產業 (QSR) 中，大部分食物都會有所謂的有效期，在食物放到備料區以後，如果超過該食物的有效期，食物就會被倒掉，以保證食物比較不會有食安上的問題，傳統上都是人工去點擊計時器，但是
“Ain’t nobody got time for that!”
如果說人員忘記點擊開始，下一次想起來再來去點，該食物的計時是完全沒有效用的
POC 為了解決這個問題， Chick-Fil-A 直接設計一個新的托盤，讓放食物的鍋子邊邊可以被 3D camera 掃描，並且直接在鍋子上給予 Bar code，這樣就可以知道是哪種食物被放上來，用以重設計時器
為了做到該功能，他們在托盤與鍋子上面架設 Camera 並且運用 NCU 進行 Bar code 偵測
AI 何時啟用 Bar code 偵測是一個不小的問題，原本他們使用 3D 相機給予的深度資訊來做 pixel counting，但是，如果 Camera 被動到，或是安裝人員安裝時，把相機安裝比預設的高兩英吋，就有可能讓 Bar code 難以被偵測 (pixel counting)，為了解決該問題，他們打算捨棄傳統的 pixel counting 改用 AI 來判斷鍋子是否安裝到托盤上
Training Data 用 3D camera 擷取沒有鍋子的影像 為了模擬真實店家情況，他們在影像中加入一些會在店內出現的東西，例如：三明治 一樣方式擷取有鍋子的影像 解析度: 1280 x 720 Neural Network Implementation 很簡單的一層 dense 一層 dropout 的 CNN 就達到不錯的效果，以下為詳細訓練的參數</description><content>&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Chick-fil-A 是一間總部位於美國喬治亞州 College Park 的美式連鎖速食店，以雞肉三明治為主 (圖片看起來其實是漢堡) ，目前有超過 2,200 間連鎖餐廳&lt;/p>
&lt;h2 id="遇到的問題">遇到的問題&lt;/h2>
&lt;p>在速食產業 (QSR) 中，大部分食物都會有所謂的有效期，在食物放到備料區以後，如果超過該食物的有效期，食物就會被倒掉，以保證食物比較不會有食安上的問題，傳統上都是人工去點擊計時器，但是&lt;/p>
&lt;blockquote>
&lt;p>“Ain’t nobody got time for that!”&lt;/p>
&lt;/blockquote>
&lt;p>如果說人員忘記點擊開始，下一次想起來再來去點，該食物的計時是完全沒有效用的&lt;/p>
&lt;h2 id="poc">POC&lt;/h2>
&lt;p>為了解決這個問題， Chick-Fil-A 直接設計一個新的托盤，讓放食物的鍋子邊邊可以被 3D camera 掃描，並且直接在鍋子上給予 Bar code，這樣就可以知道是哪種食物被放上來，用以重設計時器&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*cssV3Ug0FAmxx74YlmgTwg.png" alt="Pan and Bracket">&lt;/p>
&lt;p>為了做到該功能，他們在托盤與鍋子上面架設 Camera 並且運用 NCU 進行 Bar code 偵測&lt;/p>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*iH80Ibk3pN6HJWZxhmQmew.png" alt="NCU install">&lt;/p>
&lt;h2 id="ai">AI&lt;/h2>
&lt;p>何時啟用 Bar code 偵測是一個不小的問題，原本他們使用 3D 相機給予的深度資訊來做 pixel counting，但是，如果 Camera 被動到，或是安裝人員安裝時，把相機安裝比預設的高兩英吋，就有可能讓 Bar code 難以被偵測 (pixel counting)，為了解決該問題，他們打算捨棄傳統的 pixel counting 改用 AI 來判斷鍋子是否安裝到托盤上&lt;/p>
&lt;h3 id="training-data">Training Data&lt;/h3>
&lt;ul>
&lt;li>用 3D camera 擷取沒有鍋子的影像
&lt;ul>
&lt;li>為了模擬真實店家情況，他們在影像中加入一些會在店內出現的東西，例如：三明治&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>一樣方式擷取有鍋子的影像&lt;/li>
&lt;li>解析度: 1280 x 720&lt;/li>
&lt;/ul>
&lt;h3 id="neural-network-implementation">Neural Network Implementation&lt;/h3>
&lt;p>很簡單的一層 dense 一層 dropout 的 CNN 就達到不錯的效果，以下為詳細訓練的參數&lt;/p>
&lt;ul>
&lt;li>grayscale&lt;/li>
&lt;li>96 x 96 pixels&lt;/li>
&lt;li>2 epochs of 600 batches&lt;/li>
&lt;li>32 images per batch&lt;/li>
&lt;li>30 validation batches&lt;/li>
&lt;/ul>
&lt;h3 id="feature">Feature&lt;/h3>
&lt;p>運用鍋子的深度，以及計時器的資料，可以知道裡面有多少雞肉，那就可以知道多少肉在何時被煮起來，使用油品的紀錄也可以被知道&lt;/p>
&lt;h2 id="進化-aha-20">進化 AHA 2.0&lt;/h2>
&lt;p>完成了相關實驗後，他們要挑戰安裝到 2800 以上的店家，他們做了不少進化，例如&lt;/p>
&lt;ul>
&lt;li>如何讓平板 (顯示器)，可以在廚房惡劣的環境下還能使用，而且成本要夠低到可以擴展到所有店家&lt;/li>
&lt;li>重新設計 機器 - 相機 - 托盤，讓顯示器不會擋到相機&lt;/li>
&lt;li>加強 AI 的準確度&lt;/li>
&lt;li>壓力測試鍋子上雷射上去的 Bar code 經過刷洗後，耐用度如何&lt;/li>
&lt;li>找到更好的 Bar code，就算工作人員的手微微擋住一部分條碼也可以辨識&lt;/li>
&lt;li>加上一些傳統電腦視覺的算法，讓條碼更好被判斷&lt;/li>
&lt;li>各式 Bar code 除錯，例如：地板上有條碼，不該被混淆&lt;/li>
&lt;li>優化深度轉乘雞肉量的轉換&lt;/li>
&lt;/ul>
&lt;h3 id="硬體改進">硬體改進&lt;/h3>
&lt;p>在部署 prototype 到一些店家後，開始進行 &lt;a href="https://en.wikipedia.org/wiki/Failure_mode_and_effects_analysis">Failure Mode and Effects Analysis&lt;/a> 為了要讓他們的解決方案可以支援到 24 常駐&lt;/p>
&lt;ul>
&lt;li>一開始想辦法讓 Chrome 直接支援 Intel RealSense camera，這樣就不用 NCU 了，但是失敗&lt;/li>
&lt;li>找到夠穩定的 Chrome 平板，最後找到一個支援 Linux 的平板&lt;/li>
&lt;li>讓研究人員確定該平板跑 AI model 是穩定的&lt;/li>
&lt;/ul>
&lt;p>最後平板只有 USB, Power, Camera，他們認為已經有足夠少的 failure point ，壞掉機率也夠低，足以支撐他們的服務&lt;/p>
&lt;h2 id="ref">Ref&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://medium.com/chick-fil-atech/aha-2-0-623a0ec1cacc">AHA 2.0&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://medium.com/chick-fil-atech/edge-ai-in-a-smarter-chick-fil-a-2e2112f5e5d8">Edge AI in a Smarter Chick-fil-A&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>Chick-Fil-A Architecture</title><link>/blog/architecture-chick-fil-a/</link><pubDate>Sat, 12 Nov 2022 14:22:22 +0800</pubDate><guid>/blog/architecture-chick-fil-a/</guid><description>簡介 Chick-fil-A 是一間總部位於美國喬治亞州 College Park 的美式連鎖速食店，以雞肉三明治為主 (圖片看起來其實是漢堡) ，目前有超過 2,200 間連鎖餐廳
2017 架構 在這個階段已經有 MQTT 作為訊息傳遞 運用 Docker 去做大部分的事情，使用 Docker Swarm 使用 Fluentd 做 Event &amp;amp; Log Forwarding MQTT Docker log Redis cluster 作為 Persistence 層 IoT 透過 OAuth 流程，註冊 IoT (包含人工流程) 利用 Local OAuth 來達到本地認證，除了第一次啟動 IoT 設備以外，IoT 本人就不用再連接到網際網路也可以進行 refresh token 獲取 JWT Token 以後都透過 MQTT broker 進行溝通 Deployment flow 2018 架構 改用 K8s 因為 K8s 可以更簡單的用 Prometheus 做監控 用 Fleet 去做部署 Equirements 3 NCU with Quadcore processor, 8 GB RAM, SSD</description><content>&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Chick-fil-A 是一間總部位於美國喬治亞州 College Park 的美式連鎖速食店，以雞肉三明治為主 (圖片看起來其實是漢堡) ，目前有超過 2,200 間連鎖餐廳&lt;/p>
&lt;h2 id="2017-架構">2017 架構&lt;/h2>
&lt;ul>
&lt;li>在這個階段已經有 MQTT 作為訊息傳遞&lt;/li>
&lt;li>運用 Docker 去做大部分的事情，使用 Docker Swarm&lt;/li>
&lt;li>使用 Fluentd 做 Event &amp;amp; Log Forwarding
&lt;ul>
&lt;li>MQTT&lt;/li>
&lt;li>Docker log&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Redis cluster 作為 Persistence 層&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chick-fil-a-k8-clusters/en/slides/sl5-1531966648307.jpg" alt="Chick-Fil-A 2017 Architecture">&lt;/p>
&lt;h3 id="iot">IoT&lt;/h3>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chickfila-iot/en/slides/sl16-1515812662954.jpg" alt="Bring IoT up">
&lt;img src="https://res.infoq.com/presentations/chickfila-iot/en/slides/sl31-1515812667345.jpg" alt="OAuth">&lt;/p>
&lt;ul>
&lt;li>透過 OAuth 流程，註冊 IoT (包含人工流程)&lt;/li>
&lt;li>利用 Local OAuth 來達到本地認證，除了第一次啟動 IoT 設備以外，IoT 本人就不用再連接到網際網路也可以進行 refresh token&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chickfila-iot/en/slides/sl20-1515812665143.jpg" alt="MQTT">&lt;/p>
&lt;ul>
&lt;li>獲取 JWT Token 以後都透過 MQTT broker 進行溝通&lt;/li>
&lt;/ul>
&lt;h3 id="deployment-flow">Deployment flow&lt;/h3>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chickfila-iot/en/slides/sl35-1515812668341.jpg" alt="Deployment Flow 2017">&lt;/p>
&lt;h2 id="2018-架構">2018 架構&lt;/h2>
&lt;ul>
&lt;li>改用 K8s&lt;/li>
&lt;li>因為 K8s 可以更簡單的用 Prometheus 做監控&lt;/li>
&lt;li>用 Fleet 去做部署&lt;/li>
&lt;/ul>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chick-fil-a-k8-clusters/en/slides/sl6-1531966652646.jpg" alt="Chick-Fil-A 2018 Architecture">&lt;/p>
&lt;h2 id="equirements">Equirements&lt;/h2>
&lt;blockquote>
&lt;p>3 NCU with Quadcore processor, 8 GB RAM, SSD&lt;/p>
&lt;/blockquote>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chick-fil-a-k8-clusters/en/slides/sl11-1531966645373.jpg" alt="Equirements">&lt;/p>
&lt;h2 id="goals">Goals&lt;/h2>
&lt;ul>
&lt;li>非工程人員也可以簡單安裝&lt;/li>
&lt;li>可以遠端管理&lt;/li>
&lt;li>可以自動發現已經安裝的裝置和裝置上的 K8s 叢集&lt;/li>
&lt;li>可以自己恢復，可以做到 HA&lt;/li>
&lt;/ul>
&lt;h2 id="bare-metal-cluster-k8s-at-scale">Bare Metal Cluster K8s at scale&lt;/h2>
&lt;p>&lt;img src="https://res.infoq.com/presentations/chick-fil-a-k8-clusters/en/slides/sl14-1531966652381.jpg" alt="Bare Metal Cluster K8s at scale">&lt;/p>
&lt;h3 id="highlander">Highlander&lt;/h3>
&lt;p>為了解決三台機器在內網，開機時要找到誰當 K8s cluster 的 Leader，Chick-Fil-A 自己做了這個工具去&lt;/p>
&lt;ul>
&lt;li>確認誰是老大&lt;/li>
&lt;li>執行 RKE&lt;/li>
&lt;li>安裝一些基本的 Pods (ex: Istio&amp;hellip;)&lt;/li>
&lt;/ul>
&lt;h3 id="resetting-cluster-state">Resetting Cluster State&lt;/h3>
&lt;p>當機器有任何問題時，透過 OverlayFS 讓遠端可以去清除機器 (回到 Golden image 的狀態)&lt;/p>
&lt;h3 id="hooves-uphttpsgithubcomchick-fil-ahoovesup">&lt;a href="https://github.com/chick-fil-a/hoovesup">Hooves Up&lt;/a>&lt;/h3>
&lt;p>Chick-Fil-A 自己做的 Ansible 工具，當機器啟動時，可以自動註冊到 AWS SSM&lt;/p>
&lt;h3 id="fleet">Fleet&lt;/h3>
&lt;p>為了要部署到全部的店家中，Chick-Fil-A 遇到了幾個問題&lt;/p>
&lt;ul>
&lt;li>如果有一千的叢集，部署中有 900 個部署成功，另外 100 個失敗，那要
&lt;ul>
&lt;li>全部 rollback?&lt;/li>
&lt;li>手動解決並且處理掉那 100 個失敗?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;p>最後他們建立了 Fleet 來做部署，這邊他們使用現有的 message broker (MQTT &amp;amp; Amazon SQS)，來通知地端的 Cluster 去做部署&lt;/p>
&lt;blockquote>
&lt;p>Fleet Ecosystem Components&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>Fleet Client&lt;/li>
&lt;li>Fleet Server API
&lt;ul>
&lt;li>產生部署需要的 k8s yaml&lt;/li>
&lt;li>管理 Cluster 的 Git&lt;/li>
&lt;li>部署狀態監控&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Atlas
&lt;ul>
&lt;li>存放已經測試過的 k8s yaml&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Vessel
&lt;ul>
&lt;li>放在店家的 Agent 用來做部署&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Dashboards&lt;/li>
&lt;/ul>
&lt;h2 id="entire-flow">Entire Flow&lt;/h2>
&lt;ul>
&lt;li>在工程機房
&lt;ul>
&lt;li>使用 Golden image 去安裝系統，內建 Ansible&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>運送機器&lt;/li>
&lt;li>店家
&lt;ul>
&lt;li>安裝人員打開機器&lt;/li>
&lt;li>Sherlock 運行，確認在店內網路，並且信任機器&lt;/li>
&lt;li>Highlander，找到叢集需要的三台機器運行 RKE&lt;/li>
&lt;li>每台機器個別註冊 AWS SSM (運用 Hooves Up)&lt;/li>
&lt;li>MQTT 通知 Fleet Vessel 自動從線上抓軟體並且部署&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="ref">Ref&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.infoq.com/presentations/chick-fil-a-k8-clusters/">Chick-Fil-A-K8-Clusters&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.infoq.com/presentations/chickfila-iot/">Chick-Fil-A-IoT&lt;/a>&lt;/li>
&lt;/ul></content></item><item><title>AWS Architecture Quantiphi Real-Time Call Analytics</title><link>/blog/aws-architecture-quantiphi/</link><pubDate>Sat, 12 Nov 2022 12:26:12 +0800</pubDate><guid>/blog/aws-architecture-quantiphi/</guid><description>簡介 Quantiphi 是一家 AI 公司，提供各式解決方案，包括
金融服務 教育 健康 保險 智造 多媒體娛樂產業 能源 公共設施 零售與民生消費 網路 架構 運用 Amazon Chime Voice Connector 讓企業可以整合電話線路讓客戶服務人員可以使用軟體接聽來電 運用 Kinesis Video Stream 把來電進行串流 來電得開始與結束運用 EventBridge 來寄送通知到以下三個 SQS Queue Transcription 從 Kinesis Video Stream 讀取來電 運用 Amazon Transcribe 把語音轉文字記錄下來並存到 DynamoDB 將來電轉成 mp3 存到 S3 Keyword-extraction 截取關鍵字並存到 DynamoDB 關鍵字送回 Quantiphi Web Application Metadata-extraction 利用 Amazon Comprehend 擷取 Metadata 存到 DynamoDB 並傳回 Quantiphi Web Application 最後在 Quantiphi Web Application 就可以在服務人員接到電話前拿到上方所有資訊，讓客戶服務人員可以在接電話前就可以相對了解來電者的需求，加速整體服務，亦提高服務滿意度 架構之我建 Quantiphi 運用 API Gateway 串起整個服務，如果在沒有特別資安的考慮下面，其實可以使用 DynamoDB 的 Stream 服務，這樣 Web 服務就可以簡單的去更新該來電者的資訊給客戶服務人員</description><content>&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Quantiphi 是一家 AI 公司，提供各式解決方案，包括&lt;/p>
&lt;ul>
&lt;li>金融服務&lt;/li>
&lt;li>教育&lt;/li>
&lt;li>健康&lt;/li>
&lt;li>保險&lt;/li>
&lt;li>智造&lt;/li>
&lt;li>多媒體娛樂產業&lt;/li>
&lt;li>能源&lt;/li>
&lt;li>公共設施&lt;/li>
&lt;li>零售與民生消費&lt;/li>
&lt;li>網路&lt;/li>
&lt;/ul>
&lt;h2 id="架構">架構&lt;/h2>
&lt;p>&lt;img src="https://d1.awsstatic.com/partner-network/QuickStart/datasheets/quantiphi-real-time-analytics-architecture-diagram.ceeb134f5a044dd97d79a61c20763c8cb5a245b4.png" alt="Quantiphi AWS Architecture">&lt;/p>
&lt;ul>
&lt;li>運用 Amazon Chime Voice Connector 讓企業可以整合電話線路讓客戶服務人員可以使用軟體接聽來電&lt;/li>
&lt;li>運用 Kinesis Video Stream 把來電進行串流&lt;/li>
&lt;li>來電得開始與結束運用 EventBridge 來寄送通知到以下三個 SQS Queue
&lt;ul>
&lt;li>Transcription
&lt;ul>
&lt;li>從 Kinesis Video Stream 讀取來電&lt;/li>
&lt;li>運用 Amazon Transcribe 把語音轉文字記錄下來並存到 DynamoDB&lt;/li>
&lt;li>將來電轉成 mp3 存到 S3&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Keyword-extraction
&lt;ul>
&lt;li>截取關鍵字並存到 DynamoDB&lt;/li>
&lt;li>關鍵字送回 Quantiphi Web Application&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Metadata-extraction
&lt;ul>
&lt;li>利用 Amazon Comprehend 擷取 Metadata&lt;/li>
&lt;li>存到 DynamoDB&lt;/li>
&lt;li>並傳回 Quantiphi Web Application&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>最後在 Quantiphi Web Application 就可以在服務人員接到電話前拿到上方所有資訊，讓客戶服務人員可以在接電話前就可以相對了解來電者的需求，加速整體服務，亦提高服務滿意度&lt;/li>
&lt;/ul>
&lt;h2 id="架構之我建">架構之我建&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/QuantiphiStreamArchitecture.drawio.svg" alt="Quantiphi Stream Architecture">
Quantiphi 運用 API Gateway 串起整個服務，如果在沒有特別資安的考慮下面，其實可以使用 DynamoDB 的 Stream 服務，這樣 Web 服務就可以簡單的去更新該來電者的資訊給客戶服務人員&lt;/p>
&lt;blockquote>
&lt;p>DynamoDB Streams are charged at $0.02 per 100,000 read operations.&lt;/p>
&lt;/blockquote>
&lt;h2 id="ref">Ref&lt;/h2>
&lt;p>&lt;a href="https://aws.amazon.com/quickstart/architecture/quantiphi-real-time-call-analytics/">Quantiphi Real-Time Call Analytics on the AWS Cloud&lt;/a>&lt;/p></content></item><item><title>AWS Architecture ContactSuite</title><link>/blog/aws-architecture-contactsuite/</link><pubDate>Sat, 12 Nov 2022 11:19:38 +0800</pubDate><guid>/blog/aws-architecture-contactsuite/</guid><description> 簡介 ContactSuite 是一家做客戶服務系統的公司，讓客服可以在一個介面上完成所有客戶服務所需要的事情
可以馬上知道打過來的客戶的 email 或是 ID 整合到現有的 CRM 系統 整合現有知識庫 AWS 架構 依照服務， ContactSuite 架構可以粗分為以下三個資料流
電話或文字訊息 客戶打電話或是使用文字客服，該資訊會用 Amazon Connect 利用 IVR (互動式語音應答) 的方式，讓一些比較制式化的流程讓 lambda 處理 處理後的資料透過 Amazon ECS 轉換成客服人員有用的資訊 顯示在 ContactSuite 的頁面上 Email 透過 AWS SES 收件 Lambda 處理後送至 DyanamoDB 顯示在 ContactSuite 的頁面上 報告 ContactSuite 的系統會記錄有用的資訊到 RDS 利用 AWS SES 寄送 Report 給需要看到的人員</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/BPvr0qWpJlA" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>ContactSuite 是一家做客戶服務系統的公司，讓客服可以在一個介面上完成所有客戶服務所需要的事情&lt;/p>
&lt;ul>
&lt;li>可以馬上知道打過來的客戶的 email 或是 ID&lt;/li>
&lt;li>整合到現有的 CRM 系統&lt;/li>
&lt;li>整合現有知識庫&lt;/li>
&lt;/ul>
&lt;h2 id="aws-架構">AWS 架構&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/ContactSuiteAWSArchitecture.png" alt="ContactSuite AWS Architecture.png">&lt;/p>
&lt;p>依照服務， ContactSuite 架構可以粗分為以下三個資料流&lt;/p>
&lt;h3 id="電話或文字訊息">電話或文字訊息&lt;/h3>
&lt;ul>
&lt;li>客戶打電話或是使用文字客服，該資訊會用 Amazon Connect 利用 IVR (互動式語音應答) 的方式，讓一些比較制式化的流程讓 lambda 處理&lt;/li>
&lt;li>處理後的資料透過 Amazon ECS 轉換成客服人員有用的資訊&lt;/li>
&lt;li>顯示在 ContactSuite 的頁面上&lt;/li>
&lt;/ul>
&lt;h3 id="email">Email&lt;/h3>
&lt;ul>
&lt;li>透過 AWS SES 收件&lt;/li>
&lt;li>Lambda 處理後送至 DyanamoDB&lt;/li>
&lt;li>顯示在 ContactSuite 的頁面上&lt;/li>
&lt;/ul>
&lt;h3 id="報告">報告&lt;/h3>
&lt;ul>
&lt;li>ContactSuite 的系統會記錄有用的資訊到 RDS&lt;/li>
&lt;li>利用 AWS SES 寄送 Report 給需要看到的人員&lt;/li>
&lt;/ul></content></item><item><title>McDonald Event Driven Architecture</title><link>/blog/mcdonald-event-driven-architecture/</link><pubDate>Tue, 08 Nov 2022 21:16:20 +0800</pubDate><guid>/blog/mcdonald-event-driven-architecture/</guid><description>簡介 麥當勞，就是早餐滿福堡很好吃的那家，不服來辯
Event Driven Architecture 用於哪些系統 mobile-order progress tracking and sending marketing communications
很明顯都是很經典的應用情境，包含點餐進度追蹤和寄送一些商用訊息
Components 比較特別的是他們有工程友善的 SDK 去處理訊息，包括 schema 檢查，訊息寄送，錯誤處理等等
架構 外部訊息經過 Event Gateway 處理權限驗證等 (此處沒有說明怎樣辦到的) 經過驗證的外部訊息以及內部訊息都會打到 Producer 上面 Producer SDK 經過 Schema validation 後送到 Primary Topic 上 沒過送 Dead-letter 可以自動化處理的錯誤的由 Lambda 重送 其他人工處理後直接送到 Primary Topic 送不出去存 DynamoDB 由 Lambda 重送 Consummers 接收後一樣經過 SDK 去處理 Data governance 符合 Schema validation 就處理 不符合就丟到 Dead-letter Topic ，工人智慧處理 可以快速變更 Schema Cluster autoscaling 這裡比較好玩的是有用到 Step Function 去 Trigger Lambda 做 Partition re-assignment</description><content>&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>麥當勞，就是早餐滿福堡很好吃的那家，不服來辯&lt;/p>
&lt;h2 id="event-driven-architecture-用於哪些系統">Event Driven Architecture 用於哪些系統&lt;/h2>
&lt;blockquote>
&lt;p>mobile-order progress tracking and sending marketing communications&lt;/p>
&lt;/blockquote>
&lt;p>很明顯都是很經典的應用情境，包含點餐進度追蹤和寄送一些商用訊息&lt;/p>
&lt;h2 id="components">Components&lt;/h2>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*P0mtpk5Jk0rBQZuJl7zWIA.png" alt="Components">&lt;/p>
&lt;p>比較特別的是他們有工程友善的 SDK 去處理訊息，包括 schema 檢查，訊息寄送，錯誤處理等等&lt;/p>
&lt;h2 id="架構">架構&lt;/h2>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*gCOnmHq4jXNjSX8Jp0NgOA.jpeg" alt="Architecture">&lt;/p>
&lt;ul>
&lt;li>外部訊息經過 Event Gateway 處理權限驗證等 (此處沒有說明怎樣辦到的)&lt;/li>
&lt;li>經過驗證的外部訊息以及內部訊息都會打到 Producer 上面&lt;/li>
&lt;li>Producer SDK 經過 Schema validation 後送到 Primary Topic 上
&lt;ul>
&lt;li>沒過送 Dead-letter
&lt;ul>
&lt;li>可以自動化處理的錯誤的由 Lambda 重送&lt;/li>
&lt;li>其他人工處理後直接送到 Primary Topic&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>送不出去存 DynamoDB
&lt;ul>
&lt;li>由 Lambda 重送&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Consummers 接收後一樣經過 SDK 去處理&lt;/li>
&lt;/ul>
&lt;h2 id="data-governance">Data governance&lt;/h2>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*LvV2J6pcNdSjRf0gSA4yAw.jpeg" alt="DataGovernance">&lt;/p>
&lt;ul>
&lt;li>符合 Schema validation 就處理&lt;/li>
&lt;li>不符合就丟到 Dead-letter Topic ，工人智慧處理&lt;/li>
&lt;li>可以快速變更 Schema&lt;/li>
&lt;/ul>
&lt;h2 id="cluster-autoscaling">Cluster autoscaling&lt;/h2>
&lt;p>&lt;img src="https://miro.medium.com/max/1248/1*0WQ4CpnzhlNthWt4uGLO3g.jpeg" alt="ClusterAutoscaling">&lt;/p>
&lt;p>這裡比較好玩的是有用到 Step Function 去 Trigger Lambda 做 Partition re-assignment&lt;/p>
&lt;h2 id="domain-based-sharding">Domain-based sharding&lt;/h2>
&lt;p>&lt;img src="https://miro.medium.com/max/1400/1*cCR1EaCLRhUKG8AruzJ43g.jpeg" alt="DomainSharding">&lt;/p>
&lt;p>依照 Domain 去拆分，這邊感覺類似微服務，但又有點不太像，可以想像壞掉時的差異如下&lt;/p>
&lt;ul>
&lt;li>微服務
&lt;ul>
&lt;li>通知系統壞了但是首頁是好的&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Domain sharding
&lt;ul>
&lt;li>點餐進度通知壞了，但是還是有收到廣告通知 (前提：某通知系統 Backend 是好的以及通知系統前端是好的)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="refs">Refs&lt;/h2>
&lt;p>&lt;a href="https://medium.com/mcdonalds-technical-blog/behind-the-scenes-mcdonalds-event-driven-architecture-51a6542c0d86">Behind the scenes: McDonald’s event-driven architecture&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://medium.com/mcdonalds-technical-blog/mcdonalds-event-driven-architecture-the-data-journey-and-how-it-works-4591d108821f">McDonald’s event-driven architecture: The data journey and how it works&lt;/a>&lt;/p></content></item><item><title>AWS Architecture Study Halter</title><link>/blog/aws-architecture-halter/</link><pubDate>Sun, 06 Nov 2022 20:30:18 +0800</pubDate><guid>/blog/aws-architecture-halter/</guid><description>簡介 Halter 提供遠端管理農場的軟體，他們使用一個叫 Collar 的東西放在牛身上
用太陽能為能源 有 GPS 可以發出聲響以及震動 (驅動牛去某個地方) 觀測牛隻健康 有 APP 讓農夫建立虛擬柵欄
AWS 的架構 Collar 使用 wifi, MQTT 以及 IoT Core 將資料送到雲端 除了 wifi 以外，他們使用了 LoRa 協定，將資料送到 station 再由其送至 AWS EC2 上面的資料都會用 binary 的方式送到 Kinesis (由於有兩個 source 所以可能會重複) 去除重複資料後，利用 Lambda 並解成 JSON 格式後送到另一個 Kinesis 利用 Kinesis 做 Data aggregation (by GEO index) 將上面整理好的資料存到 S3 (此處利用農場 ID 當作 partition key) 當使用者要求牛群資料時，會傳送需求到 ECS ECS 傳送運算需求給 Athena 做運算 (十秒可以處理兩千五百萬筆資料) 完成後，ECS 從 S3 獲取 Athena 運算完成的資料，整理後傳給使用者 Key Notes LoRa 可以傳送好幾公里，其資料率可以從 27 Kbps 到 0.</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/j-lPgPGBTwQ" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Halter 提供遠端管理農場的軟體，他們使用一個叫 &lt;code>Collar&lt;/code> 的東西放在牛身上&lt;/p>
&lt;ul>
&lt;li>用太陽能為能源&lt;/li>
&lt;li>有 GPS&lt;/li>
&lt;li>可以發出聲響以及震動 (驅動牛去某個地方)&lt;/li>
&lt;li>觀測牛隻健康&lt;/li>
&lt;/ul>
&lt;p>有 APP 讓農夫建立虛擬柵欄&lt;/p>
&lt;h2 id="aws-的架構">AWS 的架構&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/HalterAWSArchitecture.png" alt="Halter AWS Architecture">&lt;/p>
&lt;ul>
&lt;li>&lt;code>Collar&lt;/code> 使用 wifi, MQTT 以及 IoT Core 將資料送到雲端&lt;/li>
&lt;li>除了 wifi 以外，他們使用了 LoRa 協定，將資料送到 station 再由其送至 AWS EC2&lt;/li>
&lt;li>上面的資料都會用 binary 的方式送到 Kinesis (由於有兩個 source 所以可能會重複)&lt;/li>
&lt;li>去除重複資料後，利用 Lambda 並解成 JSON 格式後送到另一個 Kinesis&lt;/li>
&lt;li>利用 Kinesis 做 Data aggregation (by GEO index)&lt;/li>
&lt;li>將上面整理好的資料存到 S3 (此處利用農場 ID 當作 partition key)&lt;/li>
&lt;li>當使用者要求牛群資料時，會傳送需求到 ECS&lt;/li>
&lt;li>ECS 傳送運算需求給 Athena 做運算 (十秒可以處理兩千五百萬筆資料)&lt;/li>
&lt;li>完成後，ECS 從 S3 獲取 Athena 運算完成的資料，整理後傳給使用者&lt;/li>
&lt;/ul>
&lt;h3 id="key-notes">Key Notes&lt;/h3>
&lt;ul>
&lt;li>LoRa 可以傳送好幾公里，其資料率可以從 27 Kbps 到 0.3 Kbps&lt;/li>
&lt;li>很多服務使用者其實可以等待&lt;/li>
&lt;/ul></content></item><item><title>AWS Architecture Study Mobileye</title><link>/blog/aws-architecture-mobileye/</link><pubDate>Fri, 04 Nov 2022 21:39:03 +0800</pubDate><guid>/blog/aws-architecture-mobileye/</guid><description>簡介 Mobileye 是提供汽車自駕 (ADAS) 的晶片以及演算法的廠商，依照影片的說明已經有七千萬車輛使用他們家的解決方案
AWS 的架構 車子透過 REST API 傳送資料到 AWS S3 S3 透過更時會觸發 SQS EKS 依照 SQS 的長度去擴增 worker 做資料前處理 EKS 處理完資料後分別送到 AWS Step Function S3 Elasticsearch CockroachDB 最後使用另一套 EKS 作為服務的介面 架構演進 Service Spark streaming, AWS EMR, KAFKA Lambda functions, 為了拆分服務 EKS serve Lambda functions 為了 Scale DB Postgres RDS RIDB, 查了很久，找不到是啥，以下是猜的 Reserved Instance (EC2) for AWS RDS 特規的商用資料庫 可能字幕有問題 為了查詢文件 (document) 使用 Elasticsearch 發現 Elasticsearch 對於經常更新不太友善，使用 CockroachDB 並且將其部署到 EKS 上面，使他們可以 auto scale 還享有高可用性 未來展望 雲端圖像處理 降低成本 Key Notes 為了節省成本，所以儘管有七千萬的車子使用該家產品，但是只有少部分的資料有打到雲端，每天約一千萬的資料量 由於 AWS Lambda 在同時執行 Lambda 是有其帳號上限的 (per account per region)，我猜是因為這樣才轉換到 EKS 上 架構是慢慢演化的 架構之我建 假設</description><content>
&lt;div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
&lt;iframe src="https://www.youtube.com/embed/5hjkSczrke4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video">&lt;/iframe>
&lt;/div>
&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Mobileye 是提供汽車自駕 (ADAS) 的晶片以及演算法的廠商，依照影片的說明已經有七千萬車輛使用他們家的解決方案&lt;/p>
&lt;h2 id="aws-的架構">AWS 的架構&lt;/h2>
&lt;p>&lt;img src="/img/2022/11/MobileyeAWSArchitecture.png" alt="Mobileye Architecture">&lt;/p>
&lt;ul>
&lt;li>車子透過 REST API 傳送資料到 AWS S3&lt;/li>
&lt;li>S3 透過更時會觸發 SQS&lt;/li>
&lt;li>EKS 依照 SQS 的長度去擴增 worker 做資料前處理&lt;/li>
&lt;li>EKS 處理完資料後分別送到
&lt;ul>
&lt;li>AWS Step Function&lt;/li>
&lt;li>S3&lt;/li>
&lt;li>Elasticsearch&lt;/li>
&lt;li>CockroachDB&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>最後使用另一套 EKS 作為服務的介面&lt;/li>
&lt;/ul>
&lt;h3 id="架構演進">架構演進&lt;/h3>
&lt;ul>
&lt;li>Service
&lt;ul>
&lt;li>Spark streaming, AWS EMR, KAFKA&lt;/li>
&lt;li>Lambda functions, 為了拆分服務&lt;/li>
&lt;li>EKS serve Lambda functions 為了 Scale&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>DB
&lt;ul>
&lt;li>Postgres RDS&lt;/li>
&lt;li>RIDB, 查了很久，找不到是啥，以下是猜的
&lt;ul>
&lt;li>Reserved Instance (EC2) for AWS RDS&lt;/li>
&lt;li>特規的商用資料庫&lt;/li>
&lt;li>可能字幕有問題&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>為了查詢文件 (document) 使用 Elasticsearch&lt;/li>
&lt;li>發現 Elasticsearch 對於經常更新不太友善，使用 CockroachDB 並且將其部署到 EKS 上面，使他們可以 auto scale 還享有高可用性&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="未來展望">未來展望&lt;/h3>
&lt;ul>
&lt;li>雲端圖像處理&lt;/li>
&lt;li>降低成本&lt;/li>
&lt;/ul>
&lt;h3 id="key-notes">Key Notes&lt;/h3>
&lt;ul>
&lt;li>為了節省成本，所以儘管有七千萬的車子使用該家產品，但是只有少部分的資料有打到雲端，每天約一千萬的資料量&lt;/li>
&lt;li>由於 AWS Lambda 在同時執行 Lambda 是有其帳號上限的 (per account per region)，我猜是因為這樣才轉換到 EKS 上&lt;/li>
&lt;li>架構是慢慢演化的&lt;/li>
&lt;/ul>
&lt;h3 id="架構之我建">架構之我建&lt;/h3>
&lt;p>&lt;img src="/img/2022/11/MyMobileyeIoTArchitecture.png" alt="MyMobileye IoT Architecture">&lt;/p>
&lt;p>假設&lt;/p>
&lt;ul>
&lt;li>5G 網路速度夠快&lt;/li>
&lt;li>大家都是電動車&lt;/li>
&lt;/ul>
&lt;p>我們就可以讓行駛中的車輛將影像分別傳送到&lt;/p>
&lt;ul>
&lt;li>正在充電的閒置車輛&lt;/li>
&lt;li>AWS 雲端&lt;/li>
&lt;/ul>
&lt;p>利用雲端可拓展以及先到先贏的方式，如果其他車輛已經將圖片處理完成，那我們就可以取消雲端上面的工作，用以減少成本，也可以利用基本圖像分割的方式，把大量的圖片資訊分別送給不同的閒置車輛，達到平行處理&lt;/p></content></item><item><title>AWS Architecture Study Buzzdial</title><link>/blog/aws-architecture-study-buzzdial/</link><pubDate>Wed, 26 Oct 2022 21:21:46 +0800</pubDate><guid>/blog/aws-architecture-study-buzzdial/</guid><description>簡介 Buzzdial 是一家製作電視 Live 節目即時互動的公司，可以想像主持人問答，在家中看電視的你也可以使用 App 與其他相同收看電視的人們互相交流，目前已經找不到網站，看起來應該是已經收掉了，但是還是可以找到相關資訊
遇到的問題 當遇某一特殊事件，導致大量使用者在同一時間使用服務時，需要保證網路以及伺服器可以負荷，並且該特殊事件可能不會天天發生，如果使用傳統架構會需要大量的初始建構成本
導入 AWS 的架構 架構拆想 可以看到 Buzzdial 使用了兩個分開的 ASG (auto scale group)，一個是做 Web，另一個是做管理的部分
第一次猜想 可以想像，電視製作或是主持人可以透過 API 去發送事件廣播 (broadcast)，讓所有使用者去看到或是被通知有一個互動發生 (例如：新的題目) Web App 中的 Deamon 可以透過 Logging DB 來通知使用者有新的事件 第二次猜想 We queue those records and store them in our databases to allow us to report back to clients on the success of their broadcast event, and also provide detailed business reports that we review internally.</description><content>&lt;h2 id="簡介">簡介&lt;/h2>
&lt;p>Buzzdial 是一家製作電視 Live 節目即時互動的公司，可以想像主持人問答，在家中看電視的你也可以使用 App 與其他相同收看電視的人們互相交流，目前已經找不到網站，看起來應該是已經收掉了，但是還是可以找到&lt;a href="https://nz.linkedin.com/company/buzzdial?trk=public_profile_experience-item_profile-section-card_image-click">相關資訊&lt;/a>&lt;/p>
&lt;h2 id="遇到的問題">遇到的問題&lt;/h2>
&lt;p>當遇某一特殊事件，導致大量使用者在同一時間使用服務時，需要保證網路以及伺服器可以負荷，並且該特殊事件可能不會天天發生，如果使用傳統架構會需要大量的初始建構成本&lt;/p>
&lt;h2 id="導入-aws-的架構">導入 AWS 的架構&lt;/h2>
&lt;figure class="left" >
&lt;img src="https://d1.awsstatic.com/architecture-diagrams/customers/buzzdial-arch-diag.1cd13ca7855b730ce72977f106964923745b5ca2.png" />
&lt;/figure>
&lt;h3 id="架構拆想">架構拆想&lt;/h3>
&lt;p>可以看到 Buzzdial 使用了兩個分開的 ASG (auto scale group)，一個是做 Web，另一個是做管理的部分&lt;/p>
&lt;h4 id="第一次猜想">第一次猜想&lt;/h4>
&lt;ol>
&lt;li>可以想像，電視製作或是主持人可以透過 API 去發送事件廣播 (broadcast)，讓所有使用者去看到或是被通知有一個互動發生 (例如：新的題目)&lt;/li>
&lt;li>Web App 中的 Deamon 可以透過 Logging DB 來通知使用者有新的事件&lt;/li>
&lt;/ol>
&lt;h4 id="第二次猜想">第二次猜想&lt;/h4>
&lt;blockquote>
&lt;p>We queue those records and store them in our databases to allow us to report back to clients on the success of their broadcast event, and also provide detailed business reports that we review internally. In addition, we monitor our application in real time as it scales up and down to check performance and error rates, and undertake extensive and aggressive load testing to predetermine its capabilities. If there any concerns, we rework the application and AWS infrastructure accordingly&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>很明顯 Logging DB 主要是用來留存每次互動，所以想應該有少畫一條線，是 Broadcast Tool 使用 App DB，或是利用某些方式去 Trigger App 端的更新&lt;/li>
&lt;li>在調整架構時使用了以前的資料&lt;/li>
&lt;/ol>
&lt;h4 id="有趣的點">有趣的點&lt;/h4>
&lt;blockquote>
&lt;p>the service provider can still scale in 10 to 15 minutes to support 10s of thousands of concurrent users.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>很明顯架構是使用比較傳統的 EC2 才會導致增加流量要等那麼久&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Buzzdial would have also required six full-time equivalent administrators to manage 60 physical servers, costing about US$350,000, while the AWS infrastructure requires about 20 percent of a single full-time employee’s time to administer.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>IT 人力成本在國外真的很高&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>Caching is undertaken at the Amazon EC2 level to prevent the database infrastructure from being overloaded during periods of high demand&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>使用 Local cache 而不是 redis 之類叢集快取&lt;/li>
&lt;/ul>
&lt;h3 id="架構之我建">架構之我建&lt;/h3>
&lt;h4 id="amazon-kinesis">Amazon Kinesis&lt;/h4>
&lt;p>在這個年代，如果要重新製作類似的軟體服務，可以簡單使用 &lt;a href="https://aws.amazon.com/tw/solutions/implementations/aws-streaming-data-solution-for-amazon-kinesis/">Amazon Kinesis&lt;/a> 來達成，不僅在 streaming 的部分直接幫你做掉，還可以紀錄並分析使用狀況，最後在資料整合的部分也可以使用 Kinesis Data Analytics 來達成
&lt;figure class="left" >
&lt;img src="https://d1.awsstatic.com/Solutions/Solutions%20Category%20Template%20Draft/Solution%20Architecture%20Diagrams/aws-streaming-data-using-api-gateway-architecture.1b9d28f061fe84385cb871ec58ccad18c7265d22.png" />
&lt;/figure>
&lt;/p>
&lt;h4 id="out-of-aws">Out of AWS&lt;/h4>
&lt;p>如果是比較 general 的方法，我想我會使用現在比較通用的 event sourcing 的方式，搭配讀寫分離來製作這一個軟體服務&lt;/p>
&lt;p>&lt;img src="/img/2022/10/MyBuzzdialArchitecture.svg" alt="My Buzzdial Architecture">&lt;/p>
&lt;h2 id="ref">Ref&lt;/h2>
&lt;p>&lt;a href="https://aws.amazon.com/solutions/case-studies/buzzdial/">Source of AWS case study&lt;/a>&lt;/p></content></item></channel></rss>